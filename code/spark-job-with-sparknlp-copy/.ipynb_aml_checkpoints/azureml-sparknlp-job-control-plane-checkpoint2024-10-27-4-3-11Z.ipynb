{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This Jupyter notebook should be run from within a compute instance on AzureML, in a Python kernel, specifically `Python 3.10 - SDK v2 (Python 3.10.11)`**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a client connection to the AzureML workspace\n",
    "\n",
    "The following cell creates a connection object called `ml_client` which has a connection to the AzureML workspace. You have to create this from every notebook or python script that interacts with the AzureML platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import MLClient, spark, Input, Output\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.ml.entities import UserIdentityConfiguration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this authentication mechanism if you are running this notebook from your compute instance within Azure Machine Learning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_client = MLClient.from_config(\n",
    "    DefaultAzureCredential(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, you can also run this control plane notebook from your Laptop. You need to install the python libraries in the `requirements.txt` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1731375810369
    }
   },
   "outputs": [],
   "source": [
    "ml_client = MLClient(\n",
    "    credential=DefaultAzureCredential(),\n",
    "    workspace_name=\"<YOUR_WORKSPACE_NAME>\",\n",
    "    subscription_id=\"21ff0fc0-dd2c-450d-93b7-96eeb3699b22\",\n",
    "    resource_group_name=\"<YOUR_RESOURCE_GROUP_NAME>\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the Spark-NLP jar to your working directory to be able to to add to the job cluster.\n",
    "\n",
    "You only need to do this once. The jar file needs to be in the same directory of the script that will be run as a job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the spark-nlp jar and save it locally. This needs to be done before submitting a job.\n",
    "import requests\n",
    "response = requests.get(\"https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/jars/spark-nlp-assembly-5.5.1.jar\")\n",
    "with open(\"spark-nlp-assembly-5.5.1.jar\", \"wb\") as f:\n",
    "    f.write(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Job\n",
    "\n",
    "The following cell defines the job. It is an object of [Spark Class](https://learn.microsoft.com/en-us/python/api/azure-ai-ml/azure.ai.ml.entities.spark?view=azure-python) that contains the required information to run a job:\n",
    "\n",
    "For more information about the parameters used in the job definition, [read the documentation](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-submit-spark-jobs?view=azureml-api-2&tabs=sdk#submit-a-standalone-spark-job)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1731375844443
    }
   },
   "outputs": [],
   "source": [
    "sparknlp_job_def = spark(\n",
    "    display_name=\"last-test-expect-success\",  \n",
    "    code=\"./\",\n",
    "    entry={\"file\": \"sample-spark-nlp-job.py\"},\n",
    "    driver_cores=1,\n",
    "    driver_memory=\"7g\",\n",
    "    executor_instances=1,\n",
    "    executor_cores=1,\n",
    "    executor_memory=\"7g\",\n",
    "        resources={\n",
    "        \"instance_type\": \"Standard_E4S_V3\",\n",
    "        \"runtime_version\": \"3.4\",\n",
    "    },\n",
    "    jars=[\"spark-nlp-assembly-5.5.1.jar\"],\n",
    "    environment=\"sparknlp-python-env@latest\",\n",
    "    identity=UserIdentityConfiguration()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit the job\n",
    "\n",
    "The following cell takes the job you defined above and submits it. If you are submitting multiple jobs, you may want to create separate job definition objects for clarity. You can submit more than one job, just remember that each job will spin up a Spark cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparknlp_job = ml_client.jobs.create_or_update(sparknlp_job_def)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the Job Studio URL\n",
    "\n",
    "Once you submit the job, you can navigate to it in the AzureML Studio and monitor it's progress. There are ways to do it through the SDK but for now just use the Studio. These are unattended jobs, which means you can shut down this notebook and the Compute Instance, but the job will go through it's lifecycle:\n",
    "\n",
    "- Job is submitted\n",
    "- Job is queued\n",
    "- Job is run\n",
    "- Job completes (assuming no errors)\n",
    "\n",
    "**Each job's Studio URL will be different.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1731375905109
    }
   },
   "outputs": [],
   "source": [
    "print(sparknlp_job.studio_url)"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python310-sdkv2"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   },
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
