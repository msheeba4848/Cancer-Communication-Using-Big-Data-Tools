{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Review the Results of the NLP Pretrained Model\n",
        "\n",
        "This model is very basic, but this folder shows you how to create an NLP pipeline with a pretrained model.\n",
        "\n",
        "The .py file saved the results to a parquet that is stored in our container. We are reading it back here to review."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "ba5e360d-f184-47a0-9859-76b5031b79e3",
              "statement_id": 6,
              "statement_ids": [
                6
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": {
                "numbers": {
                  "FAILED": 0,
                  "RUNNING": 0,
                  "SUCCEEDED": 0,
                  "UNKNOWN": 0
                },
                "jobs": [],
                "limit": 20,
                "rule": "ALL_DESC"
              },
              "session_id": "34",
              "normalized_state": "finished",
              "queued_time": "2024-12-07T22:33:51.8846901Z",
              "session_start_time": "2024-12-07T22:33:51.9701272Z",
              "execution_start_time": "2024-12-07T22:36:56.3489795Z",
              "execution_finish_time": "2024-12-07T22:36:58.8045775Z",
              "parent_msg_id": "452121a2-6716-4c85-910f-432f7f092868"
            },
            "text/plain": "StatementMeta(ba5e360d-f184-47a0-9859-76b5031b79e3, 34, 6, Finished, Available, Finished)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 11,
          "data": {
            "text/plain": "<pyspark.sql.session.SparkSession at 0x7fdbec8049d0>",
            "text/html": "\n            <div>\n                <p><b>SparkSession - hive</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://vm-81e25436:38315\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.3.1.5.2.20240522.3</code></dd>\n              <dt>Master</dt>\n                <dd><code>yarn</code></dd>\n              <dt>AppName</dt>\n                <dd><code>Azure ML Experiment</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        "
          },
          "metadata": {}
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1733611018934
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "workspace_default_storage_account = \"projectgstoragedfb938a3e\"\n",
        "workspace_default_container = \"azureml-blobstore-becc8696-e562-432e-af12-8a5e3e1f9b0f\"\n",
        "workspace_wasbs_base_url = f\"wasbs://{workspace_default_container}@{workspace_default_storage_account}.blob.core.windows.net/\"\n",
        "\n",
        "# the parquet path again\n",
        "output_path = f\"{workspace_wasbs_base_url}nlp_result_sample_submissions.parquet\"\n",
        "\n",
        "# Read the Parquet file back into a dataframe\n",
        "df_read_back = spark.read.parquet(output_path)\n",
        "\n",
        "# Show first 5 rows\n",
        "df_read_back.show(5)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "ba5e360d-f184-47a0-9859-76b5031b79e3",
              "statement_id": 7,
              "statement_ids": [
                7
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": {
                "numbers": {
                  "FAILED": 0,
                  "RUNNING": 0,
                  "SUCCEEDED": 2,
                  "UNKNOWN": 0
                },
                "jobs": [
                  {
                    "displayName": "showString at NativeMethodAccessorImpl.java:0",
                    "dataWritten": 0,
                    "dataRead": 736376,
                    "rowCount": 6,
                    "usageDescription": "",
                    "jobId": 1,
                    "name": "showString at NativeMethodAccessorImpl.java:0",
                    "description": "Job group for statement 7:\nworkspace_default_storage_account = \"projectgstoragedfb938a3e\"\nworkspace_default_container = \"azureml-blobstore-becc8696-e562-432e-af12-8a5e3e1f9b0f\"\nworkspace_wasbs_base_url = f\"wasbs://{workspace_default_container}@{workspace_default_storage_account}.blob.core.windows.net/\"\n\n# the parquet path again\noutput_path = f\"{workspace_wasbs_base_url}nlp_result_sample_submissions.parquet\"\n\n# Read the Parquet file back into a dataframe\ndf_read_back = spark.read.parquet(output_path)\n\n# Show first 5 rows\ndf_read_back.show(5)",
                    "submissionTime": "2024-12-07T22:37:27.696GMT",
                    "completionTime": "2024-12-07T22:37:34.669GMT",
                    "stageIds": [
                      1
                    ],
                    "jobGroup": "7",
                    "status": "SUCCEEDED",
                    "numTasks": 1,
                    "numActiveTasks": 0,
                    "numCompletedTasks": 1,
                    "numSkippedTasks": 0,
                    "numFailedTasks": 0,
                    "numKilledTasks": 0,
                    "numCompletedIndices": 1,
                    "numActiveStages": 0,
                    "numCompletedStages": 1,
                    "numSkippedStages": 0,
                    "numFailedStages": 0,
                    "killedTasksSummary": {}
                  },
                  {
                    "displayName": "parquet at NativeMethodAccessorImpl.java:0",
                    "dataWritten": 0,
                    "dataRead": 0,
                    "rowCount": 0,
                    "usageDescription": "",
                    "jobId": 0,
                    "name": "parquet at NativeMethodAccessorImpl.java:0",
                    "description": "Job group for statement 7:\nworkspace_default_storage_account = \"projectgstoragedfb938a3e\"\nworkspace_default_container = \"azureml-blobstore-becc8696-e562-432e-af12-8a5e3e1f9b0f\"\nworkspace_wasbs_base_url = f\"wasbs://{workspace_default_container}@{workspace_default_storage_account}.blob.core.windows.net/\"\n\n# the parquet path again\noutput_path = f\"{workspace_wasbs_base_url}nlp_result_sample_submissions.parquet\"\n\n# Read the Parquet file back into a dataframe\ndf_read_back = spark.read.parquet(output_path)\n\n# Show first 5 rows\ndf_read_back.show(5)",
                    "submissionTime": "2024-12-07T22:37:16.252GMT",
                    "completionTime": "2024-12-07T22:37:24.395GMT",
                    "stageIds": [
                      0
                    ],
                    "jobGroup": "7",
                    "status": "SUCCEEDED",
                    "numTasks": 1,
                    "numActiveTasks": 0,
                    "numCompletedTasks": 1,
                    "numSkippedTasks": 0,
                    "numFailedTasks": 0,
                    "numKilledTasks": 0,
                    "numCompletedIndices": 1,
                    "numActiveStages": 0,
                    "numCompletedStages": 1,
                    "numSkippedStages": 0,
                    "numFailedStages": 0,
                    "killedTasksSummary": {}
                  }
                ],
                "limit": 20,
                "rule": "ALL_DESC"
              },
              "session_id": "34",
              "normalized_state": "finished",
              "queued_time": "2024-12-07T22:37:15.1531815Z",
              "session_start_time": null,
              "execution_start_time": "2024-12-07T22:37:15.2643756Z",
              "execution_finish_time": "2024-12-07T22:37:36.3283739Z",
              "parent_msg_id": "767d99b7-e057-4487-9430-a384d63dd550"
            },
            "text/plain": "StatementMeta(ba5e360d-f184-47a0-9859-76b5031b79e3, 34, 7, Finished, Available, Finished)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n|                text|            document|            sentence|               token|               spell|              lemmas|               stems|                 pos|\n+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n|Hi, I hope this i...|[{document, 0, 85...|[{document, 0, 23...|[{token, 0, 1, Hi...|[{token, 0, 1, Hi...|[{token, 0, 1, Hi...|[{token, 0, 1, hi...|[{pos, 0, 1, NNP,...|\n|33 male, i have d...|[{document, 0, 27...|[{document, 0, 68...|[{token, 0, 1, 33...|[{token, 0, 1, 33...|[{token, 0, 1, 33...|[{token, 0, 1, 33...|[{pos, 0, 1, CD, ...|\n|           [removed]|[{document, 0, 8,...|[{document, 0, 8,...|[{token, 0, 8, [r...|[{token, 0, 8, [r...|[{token, 0, 8, [r...|[{token, 0, 8, [r...|[{pos, 0, 8, NN, ...|\n|           [removed]|[{document, 0, 8,...|[{document, 0, 8,...|[{token, 0, 8, [r...|[{token, 0, 8, [r...|[{token, 0, 8, [r...|[{token, 0, 8, [r...|[{pos, 0, 8, NN, ...|\n|83F, Cancer dx (u...|[{document, 0, 27...|[{document, 0, 16...|[{token, 0, 2, 83...|[{token, 0, 2, 83...|[{token, 0, 2, 83...|[{token, 0, 2, 83...|[{pos, 0, 2, CD, ...|\n+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\nonly showing top 5 rows\n\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1733611056493
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_path = f\"{workspace_wasbs_base_url}nlp_sentiment_sample_submissions.parquet\"\n",
        "# Read the Parquet file back into a dataframe\n",
        "df_read_back = spark.read.parquet(output_path)\n",
        "\n",
        "# Show first 5 rows\n",
        "df_read_back.show(5)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "ba5e360d-f184-47a0-9859-76b5031b79e3",
              "statement_id": 8,
              "statement_ids": [
                8
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": {
                "numbers": {
                  "FAILED": 0,
                  "RUNNING": 0,
                  "SUCCEEDED": 2,
                  "UNKNOWN": 0
                },
                "jobs": [
                  {
                    "displayName": "showString at NativeMethodAccessorImpl.java:0",
                    "dataWritten": 0,
                    "dataRead": 386727,
                    "rowCount": 6,
                    "usageDescription": "",
                    "jobId": 3,
                    "name": "showString at NativeMethodAccessorImpl.java:0",
                    "description": "Job group for statement 8:\noutput_path = f\"{workspace_wasbs_base_url}nlp_sentiment_sample_submissions.parquet\"\n# Read the Parquet file back into a dataframe\ndf_read_back = spark.read.parquet(output_path)\n\n# Show first 5 rows\ndf_read_back.show(5)",
                    "submissionTime": "2024-12-07T22:37:40.897GMT",
                    "completionTime": "2024-12-07T22:37:44.663GMT",
                    "stageIds": [
                      3
                    ],
                    "jobGroup": "8",
                    "status": "SUCCEEDED",
                    "numTasks": 1,
                    "numActiveTasks": 0,
                    "numCompletedTasks": 1,
                    "numSkippedTasks": 0,
                    "numFailedTasks": 0,
                    "numKilledTasks": 0,
                    "numCompletedIndices": 1,
                    "numActiveStages": 0,
                    "numCompletedStages": 1,
                    "numSkippedStages": 0,
                    "numFailedStages": 0,
                    "killedTasksSummary": {}
                  },
                  {
                    "displayName": "parquet at NativeMethodAccessorImpl.java:0",
                    "dataWritten": 0,
                    "dataRead": 0,
                    "rowCount": 0,
                    "usageDescription": "",
                    "jobId": 2,
                    "name": "parquet at NativeMethodAccessorImpl.java:0",
                    "description": "Job group for statement 8:\noutput_path = f\"{workspace_wasbs_base_url}nlp_sentiment_sample_submissions.parquet\"\n# Read the Parquet file back into a dataframe\ndf_read_back = spark.read.parquet(output_path)\n\n# Show first 5 rows\ndf_read_back.show(5)",
                    "submissionTime": "2024-12-07T22:37:40.092GMT",
                    "completionTime": "2024-12-07T22:37:40.527GMT",
                    "stageIds": [
                      2
                    ],
                    "jobGroup": "8",
                    "status": "SUCCEEDED",
                    "numTasks": 1,
                    "numActiveTasks": 0,
                    "numCompletedTasks": 1,
                    "numSkippedTasks": 0,
                    "numFailedTasks": 0,
                    "numKilledTasks": 0,
                    "numCompletedIndices": 1,
                    "numActiveStages": 0,
                    "numCompletedStages": 1,
                    "numSkippedStages": 0,
                    "numFailedStages": 0,
                    "killedTasksSummary": {}
                  }
                ],
                "limit": 20,
                "rule": "ALL_DESC"
              },
              "session_id": "34",
              "normalized_state": "finished",
              "queued_time": "2024-12-07T22:37:39.797957Z",
              "session_start_time": null,
              "execution_start_time": "2024-12-07T22:37:39.9254575Z",
              "execution_finish_time": "2024-12-07T22:37:46.2766619Z",
              "parent_msg_id": "aeef6666-81c2-4de7-9157-c8a99bb9b76a"
            },
            "text/plain": "StatementMeta(ba5e360d-f184-47a0-9859-76b5031b79e3, 34, 8, Finished, Available, Finished)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n|                text|            document|            sentence|               token|             checked|           sentiment|\n+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n|Hi, I hope this i...|[{document, 0, 85...|[{document, 0, 23...|[{token, 0, 1, Hi...|[{token, 0, 1, Hi...|[{sentiment, 0, 2...|\n|33 male, i have d...|[{document, 0, 27...|[{document, 0, 68...|[{token, 0, 1, 33...|[{token, 0, 1, 33...|[{sentiment, 0, 6...|\n|           [removed]|[{document, 0, 8,...|[{document, 0, 8,...|[{token, 0, 8, [r...|[{token, 0, 8, [r...|[{sentiment, 0, 8...|\n|           [removed]|[{document, 0, 8,...|[{document, 0, 8,...|[{token, 0, 8, [r...|[{token, 0, 8, [r...|[{sentiment, 0, 8...|\n|83F, Cancer dx (u...|[{document, 0, 27...|[{document, 0, 16...|[{token, 0, 2, 83...|[{token, 0, 2, 83...|[{sentiment, 0, 1...|\n+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\nonly showing top 5 rows\n\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1733611066380
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_path = f\"{workspace_wasbs_base_url}nlp_sentiment_results_sample_submissions.parquet\"\n",
        "# Read the Parquet file back into a dataframe\n",
        "df_read_back = spark.read.parquet(output_path)\n",
        "\n",
        "# Show first 5 rows\n",
        "df_read_back.show(5)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "ba5e360d-f184-47a0-9859-76b5031b79e3",
              "statement_id": 9,
              "statement_ids": [
                9
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": {
                "numbers": {
                  "FAILED": 0,
                  "RUNNING": 0,
                  "SUCCEEDED": 2,
                  "UNKNOWN": 0
                },
                "jobs": [
                  {
                    "displayName": "showString at NativeMethodAccessorImpl.java:0",
                    "dataWritten": 0,
                    "dataRead": 45287,
                    "rowCount": 6,
                    "usageDescription": "",
                    "jobId": 5,
                    "name": "showString at NativeMethodAccessorImpl.java:0",
                    "description": "Job group for statement 9:\noutput_path = f\"{workspace_wasbs_base_url}nlp_sentiment_results_sample_submissions.parquet\"\n# Read the Parquet file back into a dataframe\ndf_read_back = spark.read.parquet(output_path)\n\n# Show first 5 rows\ndf_read_back.show(5)",
                    "submissionTime": "2024-12-07T22:50:15.577GMT",
                    "completionTime": "2024-12-07T22:50:15.847GMT",
                    "stageIds": [
                      5
                    ],
                    "jobGroup": "9",
                    "status": "SUCCEEDED",
                    "numTasks": 1,
                    "numActiveTasks": 0,
                    "numCompletedTasks": 1,
                    "numSkippedTasks": 0,
                    "numFailedTasks": 0,
                    "numKilledTasks": 0,
                    "numCompletedIndices": 1,
                    "numActiveStages": 0,
                    "numCompletedStages": 1,
                    "numSkippedStages": 0,
                    "numFailedStages": 0,
                    "killedTasksSummary": {}
                  },
                  {
                    "displayName": "parquet at NativeMethodAccessorImpl.java:0",
                    "dataWritten": 0,
                    "dataRead": 0,
                    "rowCount": 0,
                    "usageDescription": "",
                    "jobId": 4,
                    "name": "parquet at NativeMethodAccessorImpl.java:0",
                    "description": "Job group for statement 9:\noutput_path = f\"{workspace_wasbs_base_url}nlp_sentiment_results_sample_submissions.parquet\"\n# Read the Parquet file back into a dataframe\ndf_read_back = spark.read.parquet(output_path)\n\n# Show first 5 rows\ndf_read_back.show(5)",
                    "submissionTime": "2024-12-07T22:50:15.254GMT",
                    "completionTime": "2024-12-07T22:50:15.427GMT",
                    "stageIds": [
                      4
                    ],
                    "jobGroup": "9",
                    "status": "SUCCEEDED",
                    "numTasks": 1,
                    "numActiveTasks": 0,
                    "numCompletedTasks": 1,
                    "numSkippedTasks": 0,
                    "numFailedTasks": 0,
                    "numKilledTasks": 0,
                    "numCompletedIndices": 1,
                    "numActiveStages": 0,
                    "numCompletedStages": 1,
                    "numSkippedStages": 0,
                    "numFailedStages": 0,
                    "killedTasksSummary": {}
                  }
                ],
                "limit": 20,
                "rule": "ALL_DESC"
              },
              "session_id": "34",
              "normalized_state": "finished",
              "queued_time": "2024-12-07T22:50:14.8280611Z",
              "session_start_time": null,
              "execution_start_time": "2024-12-07T22:50:15.0672231Z",
              "execution_finish_time": "2024-12-07T22:50:16.6465249Z",
              "parent_msg_id": "a0e4d703-b177-45ba-9335-160e7c68e29b"
            },
            "text/plain": "StatementMeta(ba5e360d-f184-47a0-9859-76b5031b79e3, 34, 9, Finished, Available, Finished)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "+--------------------+--------------------+\n|                text|              result|\n+--------------------+--------------------+\n|Hi, I hope this i...|[negative, positi...|\n|33 male, i have d...|[negative, positi...|\n|           [removed]|                [na]|\n|           [removed]|                [na]|\n|83F, Cancer dx (u...|[negative, negati...|\n+--------------------+--------------------+\nonly showing top 5 rows\n\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1733611816760
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_read_back.printSchema()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "ba5e360d-f184-47a0-9859-76b5031b79e3",
              "statement_id": 12,
              "statement_ids": [
                12
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": {
                "numbers": {
                  "FAILED": 0,
                  "RUNNING": 0,
                  "SUCCEEDED": 0,
                  "UNKNOWN": 0
                },
                "jobs": [],
                "limit": 20,
                "rule": "ALL_DESC"
              },
              "session_id": "34",
              "normalized_state": "finished",
              "queued_time": "2024-12-07T23:00:13.9282137Z",
              "session_start_time": null,
              "execution_start_time": "2024-12-07T23:00:14.1342449Z",
              "execution_finish_time": "2024-12-07T23:00:15.3817134Z",
              "parent_msg_id": "6bf65b0e-1549-4fa4-8389-a7357a0f454e"
            },
            "text/plain": "StatementMeta(ba5e360d-f184-47a0-9859-76b5031b79e3, 34, 12, Finished, Available, Finished)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "root\n |-- text: string (nullable = true)\n |-- result: array (nullable = true)\n |    |-- element: string (containsNull = true)\n\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1733612415489
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_read_back[result])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "synapse_pyspark",
      "language": "Python",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0",
      "mimetype": "text/x-python",
      "file_extension": ".py",
      "pygments_lexer": "ipython",
      "codemirror_mode": "ipython",
      "nbconvert_exporter": "python"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "synapse_pyspark"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}