{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**This Jupyter notebook should be run from within a compute instance on AzureML, in a Python kernel, specifically `Python 3.10 - SDK v2 (Python 3.10.11)`**. "
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a client connection to the AzureML workspace\n",
        "\n",
        "The following cell creates a connection object called `ml_client` which has a connection to the AzureML workspace. You have to create this from every notebook or python script that interacts with the AzureML platform."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import MLClient, spark, Input, Output\n",
        "from azure.identity import DefaultAzureCredential\n",
        "from azure.ai.ml.entities import UserIdentityConfiguration"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "1c77c5be-01d5-4a73-be0b-1c872b18023f",
              "statement_id": 6,
              "statement_ids": [
                6
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": {
                "numbers": {
                  "RUNNING": 0,
                  "SUCCEEDED": 0,
                  "UNKNOWN": 0,
                  "FAILED": 0
                },
                "jobs": [],
                "limit": 20,
                "rule": "ALL_DESC"
              },
              "session_id": "3",
              "normalized_state": "finished",
              "queued_time": "2024-11-27T04:29:53.2122986Z",
              "session_start_time": "2024-11-27T04:29:53.2494665Z",
              "execution_start_time": "2024-11-27T04:37:19.3602769Z",
              "execution_finish_time": "2024-11-27T04:37:36.4043496Z",
              "parent_msg_id": "83ba2d85-ea56-4aca-9e9b-3beb7653def0"
            },
            "text/plain": "StatementMeta(1c77c5be-01d5-4a73-be0b-1c872b18023f, 3, 6, Finished, Available, Finished)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1732682256500
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use this authentication mechanism if you are running this notebook from your compute instance within Azure Machine Learning:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#ml_client = MLClient.from_config(\n",
        "#    DefaultAzureCredential(),\n",
        "#)\n"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "1c77c5be-01d5-4a73-be0b-1c872b18023f",
              "statement_id": 7,
              "statement_ids": [
                7
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": {
                "numbers": {
                  "RUNNING": 0,
                  "SUCCEEDED": 0,
                  "UNKNOWN": 0,
                  "FAILED": 0
                },
                "jobs": [],
                "limit": 20,
                "rule": "ALL_DESC"
              },
              "session_id": "3",
              "normalized_state": "finished",
              "queued_time": "2024-11-27T04:37:43.3020589Z",
              "session_start_time": null,
              "execution_start_time": "2024-11-27T04:37:43.4990835Z",
              "execution_finish_time": "2024-11-27T04:37:45.1106938Z",
              "parent_msg_id": "4b6f4bea-2791-4826-92e7-87174dcbcbb5"
            },
            "text/plain": "StatementMeta(1c77c5be-01d5-4a73-be0b-1c872b18023f, 3, 7, Finished, Available, Finished)"
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "ValidationException",
          "evalue": "We could not find config.json in: . or in its parent directories. Please provide the full path to the config file or ensure that config.json exists in the parent directories.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValidationException\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ml_client \u001b[38;5;241m=\u001b[39m \u001b[43mMLClient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mDefaultAzureCredential\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/cluster-env/env/lib/python3.10/site-packages/azure/ai/ml/_ml_client.py:736\u001b[0m, in \u001b[0;36mMLClient.from_config\u001b[0;34m(cls, credential, path, file_name, **kwargs)\u001b[0m\n\u001b[1;32m    730\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m found_path:\n\u001b[1;32m    731\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    732\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWe could not find config.json in: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m or in its parent directories. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    733\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease provide the full path to the config file or ensure that \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    734\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig.json exists in the parent directories.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    735\u001b[0m         )\n\u001b[0;32m--> 736\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ValidationException(\n\u001b[1;32m    737\u001b[0m             message\u001b[38;5;241m=\u001b[39mmsg\u001b[38;5;241m.\u001b[39mformat(path),\n\u001b[1;32m    738\u001b[0m             no_personal_data_message\u001b[38;5;241m=\u001b[39mmsg\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[path]\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    739\u001b[0m             target\u001b[38;5;241m=\u001b[39mErrorTarget\u001b[38;5;241m.\u001b[39mGENERAL,\n\u001b[1;32m    740\u001b[0m             error_category\u001b[38;5;241m=\u001b[39mErrorCategory\u001b[38;5;241m.\u001b[39mUSER_ERROR,\n\u001b[1;32m    741\u001b[0m         )\n\u001b[1;32m    743\u001b[0m subscription_id, resource_group, workspace_name \u001b[38;5;241m=\u001b[39m MLClient\u001b[38;5;241m.\u001b[39m_get_workspace_info(found_path)\n\u001b[1;32m    745\u001b[0m module_logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound the config file in: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, found_path)\n",
            "\u001b[0;31mValidationException\u001b[0m: We could not find config.json in: . or in its parent directories. Please provide the full path to the config file or ensure that config.json exists in the parent directories."
          ]
        }
      ],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1732682265285
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "However, you can also run this control plane notebook from your Laptop. You need to install the python libraries in the `requirements.txt` file."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "ml_client = MLClient(\n",
        "    credential=DefaultAzureCredential(),\n",
        "    workspace_name=\"project-group-35\",\n",
        "    subscription_id=\"21ff0fc0-dd2c-450d-93b7-96eeb3699b22\",\n",
        "    resource_group_name=\"project-group-35\"\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "1c77c5be-01d5-4a73-be0b-1c872b18023f",
              "statement_id": 8,
              "statement_ids": [
                8
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": {
                "numbers": {
                  "RUNNING": 0,
                  "SUCCEEDED": 0,
                  "UNKNOWN": 0,
                  "FAILED": 0
                },
                "jobs": [],
                "limit": 20,
                "rule": "ALL_DESC"
              },
              "session_id": "3",
              "normalized_state": "finished",
              "queued_time": "2024-11-27T04:44:43.586598Z",
              "session_start_time": null,
              "execution_start_time": "2024-11-27T04:44:43.8438047Z",
              "execution_finish_time": "2024-11-27T04:44:50.3197405Z",
              "parent_msg_id": "c4a66ee6-92fd-4d96-abb0-72f2ab818212"
            },
            "text/plain": "StatementMeta(1c77c5be-01d5-4a73-be0b-1c872b18023f, 3, 8, Finished, Available, Finished)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1732682690444
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download the Spark-NLP jar to your working directory to be able to to add to the job cluster.\n",
        "\n",
        "You only need to do this once. The jar file needs to be in the same directory of the script that will be run as a job."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the spark-nlp jar and save it locally. This needs to be done before submitting a job.\n",
        "import requests\n",
        "response = requests.get(\"https://repo1.maven.org/maven2/com/johnsnowlabs/nlp/spark-nlp_2.12/5.0.2/spark-nlp_2.12-5.0.2.jar\")\n",
        "with open(\"spark-nlp_2.12-5.0.2.jar\", \"wb\") as f:\n",
        "    f.write(response.content)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the Job\n",
        "\n",
        "The following cell defines the job. It is an object of [Spark Class](https://learn.microsoft.com/en-us/python/api/azure-ai-ml/azure.ai.ml.entities.spark?view=azure-python) that contains the required information to run a job:\n",
        "\n",
        "For more information about the parameters used in the job definition, [read the documentation](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-submit-spark-jobs?view=azureml-api-2&tabs=sdk#submit-a-standalone-spark-job)."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "sparknlp_job_def = spark(\n",
        "    display_name=\"last-test-expect-success\",  \n",
        "    code=\"./\",\n",
        "    entry={\"file\": \"sample-spark-nlp-job.py\"},\n",
        "    driver_cores=1,\n",
        "    driver_memory=\"7g\",\n",
        "    executor_instances=1,\n",
        "    executor_cores=1,\n",
        "    executor_memory=\"7g\",\n",
        "        resources={\n",
        "        \"instance_type\": \"Standard_E4S_V3\",\n",
        "        \"runtime_version\": \"3.4\",\n",
        "    },\n",
        "    jars=[\"spark-nlp_2.12-5.0.2.jar\"],\n",
        "    environment=\"sparknlp-python-env@latest\",\n",
        "    identity=UserIdentityConfiguration()\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1731375844443
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Submit the job\n",
        "\n",
        "The following cell takes the job you defined above and submits it. If you are submitting multiple jobs, you may want to create separate job definition objects for clarity. You can submit more than one job, just remember that each job will spin up a Spark cluster."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "sparknlp_job = ml_client.jobs.create_or_update(sparknlp_job_def)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get the Job Studio URL\n",
        "\n",
        "Once you submit the job, you can navigate to it in the AzureML Studio and monitor it's progress. There are ways to do it through the SDK but for now just use the Studio. These are unattended jobs, which means you can shut down this notebook and the Compute Instance, but the job will go through it's lifecycle:\n",
        "\n",
        "- Job is submitted\n",
        "- Job is queued\n",
        "- Job is run\n",
        "- Job completes (assuming no errors)\n",
        "\n",
        "**Each job's Studio URL will be different.**"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "print(sparknlp_job.studio_url)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1731375905109
        }
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "synapse_pyspark"
    },
    "kernelspec": {
      "name": "synapse_pyspark",
      "language": "Python",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0",
      "mimetype": "text/x-python",
      "file_extension": ".py",
      "pygments_lexer": "ipython",
      "codemirror_mode": "ipython",
      "nbconvert_exporter": "python"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 2
}