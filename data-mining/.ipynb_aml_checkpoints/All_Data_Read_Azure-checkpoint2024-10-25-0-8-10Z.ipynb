{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Queries Running on entire Dataset in Azure \n",
        "\n",
        "Using the Azure Blob location with the project data: wasbs://reddit-project@dsan6000fall2024.blob.core.windows.net/<DIRECTORY>/."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "ba5e360d-f184-47a0-9859-76b5031b79e3",
              "statement_id": 6,
              "statement_ids": [
                6
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": {
                "numbers": {
                  "FAILED": 0,
                  "RUNNING": 0,
                  "UNKNOWN": 0,
                  "SUCCEEDED": 0
                },
                "jobs": [],
                "limit": 20,
                "rule": "ALL_DESC"
              },
              "session_id": "6",
              "normalized_state": "finished",
              "queued_time": "2024-11-24T22:29:40.7579418Z",
              "session_start_time": "2024-11-24T22:29:40.796611Z",
              "execution_start_time": "2024-11-24T22:36:47.8889936Z",
              "execution_finish_time": "2024-11-24T22:36:50.33824Z",
              "parent_msg_id": "2f8f6b88-9ba2-4226-98c8-6093c3e96454"
            },
            "text/plain": "StatementMeta(ba5e360d-f184-47a0-9859-76b5031b79e3, 6, 6, Finished, Available, Finished)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 11,
          "data": {
            "text/plain": "<pyspark.sql.session.SparkSession at 0x7fd4a848e200>",
            "text/html": "\n            <div>\n                <p><b>SparkSession - hive</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://vm-2e424325:40591\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.3.1.5.2.20240522.3</code></dd>\n              <dt>Master</dt>\n                <dd><code>yarn</code></dd>\n              <dt>AppName</dt>\n                <dd><code>Azure ML Experiment</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        "
          },
          "metadata": {}
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1732487810476
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Set up Data Configuration"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "blob_account_name = \"dsan6000fall2024\"\n",
        "blob_container_name = \"reddit-project\"\n",
        "wasbs_base_url = (\n",
        "    f\"wasbs://{blob_container_name}@{blob_account_name}.blob.core.windows.net/\"\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "ba5e360d-f184-47a0-9859-76b5031b79e3",
              "statement_id": 7,
              "statement_ids": [
                7
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": {
                "numbers": {
                  "FAILED": 0,
                  "RUNNING": 0,
                  "UNKNOWN": 0,
                  "SUCCEEDED": 0
                },
                "jobs": [],
                "limit": 20,
                "rule": "ALL_DESC"
              },
              "session_id": "6",
              "normalized_state": "finished",
              "queued_time": "2024-11-24T22:36:55.9945299Z",
              "session_start_time": null,
              "execution_start_time": "2024-11-24T22:36:56.1318214Z",
              "execution_finish_time": "2024-11-24T22:36:56.4484067Z",
              "parent_msg_id": "f174ef3a-ec49-42fc-9e72-a1a621a465fb"
            },
            "text/plain": "StatementMeta(ba5e360d-f184-47a0-9859-76b5031b79e3, 6, 7, Finished, Available, Finished)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1732487816563
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Reading in a single parquet file "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "comments_path = \"202306-202407/comments/\"\n",
        "submissions_path = \"202306-202407/submissions/\""
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "ba5e360d-f184-47a0-9859-76b5031b79e3",
              "statement_id": 8,
              "statement_ids": [
                8
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": {
                "numbers": {
                  "FAILED": 0,
                  "RUNNING": 0,
                  "UNKNOWN": 0,
                  "SUCCEEDED": 0
                },
                "jobs": [],
                "limit": 20,
                "rule": "ALL_DESC"
              },
              "session_id": "6",
              "normalized_state": "finished",
              "queued_time": "2024-11-24T22:36:58.4406719Z",
              "session_start_time": null,
              "execution_start_time": "2024-11-24T22:36:58.5650334Z",
              "execution_finish_time": "2024-11-24T22:36:58.8756973Z",
              "parent_msg_id": "2fdf2345-42e2-4f94-ad29-5a60100aaf57"
            },
            "text/plain": "StatementMeta(ba5e360d-f184-47a0-9859-76b5031b79e3, 6, 8, Finished, Available, Finished)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1732487819018
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Test on a single file only (random file)\n",
        "\n",
        "# comments_single = \"yyyy=2023/mm=11/comments_RC_2023-11.zst_9.parquet\"\n",
        "# submissions_single = \"yyyy=2023/mm=11/submissions_RS_2023-11.zst_36.parquet\""
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "ba5e360d-f184-47a0-9859-76b5031b79e3",
              "statement_id": 10,
              "statement_ids": [
                10
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": {
                "numbers": {
                  "RUNNING": 0,
                  "UNKNOWN": 0,
                  "SUCCEEDED": 0,
                  "FAILED": 0
                },
                "jobs": [],
                "limit": 20,
                "rule": "ALL_DESC"
              },
              "session_id": "4",
              "normalized_state": "finished",
              "queued_time": "2024-11-24T21:44:04.1045073Z",
              "session_start_time": null,
              "execution_start_time": "2024-11-24T21:44:04.5351283Z",
              "execution_finish_time": "2024-11-24T21:44:05.6603384Z",
              "parent_msg_id": "6c207f9f-1ee9-4fc8-bb78-7c42dc1b88f5"
            },
            "text/plain": "StatementMeta(ba5e360d-f184-47a0-9859-76b5031b79e3, 4, 10, Finished, Available, Finished)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1732484645737
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# comments_single_df = spark.read.parquet(f\"{wasbs_base_url}{comments_path}{comments_single}\")\n",
        "# submissions_single_df = spark.read.parquet(f\"{wasbs_base_url}{submissions_path}{submissions_single}\")"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "ba5e360d-f184-47a0-9859-76b5031b79e3",
              "statement_id": 11,
              "statement_ids": [
                11
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": {
                "numbers": {
                  "RUNNING": 0,
                  "UNKNOWN": 0,
                  "SUCCEEDED": 2,
                  "FAILED": 0
                },
                "jobs": [
                  {
                    "displayName": "parquet at NativeMethodAccessorImpl.java:0",
                    "dataWritten": 0,
                    "dataRead": 0,
                    "rowCount": 0,
                    "usageDescription": "",
                    "jobId": 1,
                    "name": "parquet at NativeMethodAccessorImpl.java:0",
                    "description": "Job group for statement 11:\ncomments_single_df = spark.read.parquet(f\"{wasbs_base_url}{comments_path}{comments_single}\")\nsubmissions_single_df = spark.read.parquet(f\"{wasbs_base_url}{submissions_path}{submissions_single}\")",
                    "submissionTime": "2024-11-24T21:44:15.165GMT",
                    "completionTime": "2024-11-24T21:44:15.367GMT",
                    "stageIds": [
                      1
                    ],
                    "jobGroup": "11",
                    "status": "SUCCEEDED",
                    "numTasks": 1,
                    "numActiveTasks": 0,
                    "numCompletedTasks": 1,
                    "numSkippedTasks": 0,
                    "numFailedTasks": 0,
                    "numKilledTasks": 0,
                    "numCompletedIndices": 1,
                    "numActiveStages": 0,
                    "numCompletedStages": 1,
                    "numSkippedStages": 0,
                    "numFailedStages": 0,
                    "killedTasksSummary": {}
                  },
                  {
                    "displayName": "parquet at NativeMethodAccessorImpl.java:0",
                    "dataWritten": 0,
                    "dataRead": 0,
                    "rowCount": 0,
                    "usageDescription": "",
                    "jobId": 0,
                    "name": "parquet at NativeMethodAccessorImpl.java:0",
                    "description": "Job group for statement 11:\ncomments_single_df = spark.read.parquet(f\"{wasbs_base_url}{comments_path}{comments_single}\")\nsubmissions_single_df = spark.read.parquet(f\"{wasbs_base_url}{submissions_path}{submissions_single}\")",
                    "submissionTime": "2024-11-24T21:44:07.684GMT",
                    "completionTime": "2024-11-24T21:44:13.833GMT",
                    "stageIds": [
                      0
                    ],
                    "jobGroup": "11",
                    "status": "SUCCEEDED",
                    "numTasks": 1,
                    "numActiveTasks": 0,
                    "numCompletedTasks": 1,
                    "numSkippedTasks": 0,
                    "numFailedTasks": 0,
                    "numKilledTasks": 0,
                    "numCompletedIndices": 1,
                    "numActiveStages": 0,
                    "numCompletedStages": 1,
                    "numSkippedStages": 0,
                    "numFailedStages": 0,
                    "killedTasksSummary": {}
                  }
                ],
                "limit": 20,
                "rule": "ALL_DESC"
              },
              "session_id": "4",
              "normalized_state": "finished",
              "queued_time": "2024-11-24T21:44:06.6202349Z",
              "session_start_time": null,
              "execution_start_time": "2024-11-24T21:44:06.7456341Z",
              "execution_finish_time": "2024-11-24T21:44:16.8325875Z",
              "parent_msg_id": "0b2d1f97-36cf-444c-90d1-40ea2ad89e2d"
            },
            "text/plain": "StatementMeta(ba5e360d-f184-47a0-9859-76b5031b79e3, 4, 11, Finished, Available, Finished)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1732484656911
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Initial exploration\n",
        "Schema & Row count\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# comments_single_df.printSchema()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "ba5e360d-f184-47a0-9859-76b5031b79e3",
              "statement_id": 12,
              "statement_ids": [
                12
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": {
                "numbers": {
                  "RUNNING": 0,
                  "UNKNOWN": 0,
                  "SUCCEEDED": 0,
                  "FAILED": 0
                },
                "jobs": [],
                "limit": 20,
                "rule": "ALL_DESC"
              },
              "session_id": "4",
              "normalized_state": "finished",
              "queued_time": "2024-11-24T21:44:18.2265333Z",
              "session_start_time": null,
              "execution_start_time": "2024-11-24T21:44:18.3567245Z",
              "execution_finish_time": "2024-11-24T21:44:18.6996816Z",
              "parent_msg_id": "69992a1e-99c8-4152-9e12-90d07ca86d39"
            },
            "text/plain": "StatementMeta(ba5e360d-f184-47a0-9859-76b5031b79e3, 4, 12, Finished, Available, Finished)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "root\n |-- author: string (nullable = true)\n |-- author_flair_css_class: string (nullable = true)\n |-- author_flair_text: string (nullable = true)\n |-- body: string (nullable = true)\n |-- controversiality: long (nullable = true)\n |-- created_utc: long (nullable = true)\n |-- distinguished: string (nullable = true)\n |-- edited: double (nullable = true)\n |-- gilded: long (nullable = true)\n |-- id: string (nullable = true)\n |-- link_id: string (nullable = true)\n |-- parent_id: string (nullable = true)\n |-- retrieved_on: long (nullable = true)\n |-- score: long (nullable = true)\n |-- stickied: boolean (nullable = true)\n |-- subreddit: string (nullable = true)\n |-- subreddit_id: string (nullable = true)\n\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1732484658786
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# comments_row_count = comments_single_df.count()\n",
        "# comment_col_count = len(comments_single_df.columns)\n",
        "# print(f\"shape of the comments dataframe is {comments_row_count:,}x{comment_col_count}\")"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "ba5e360d-f184-47a0-9859-76b5031b79e3",
              "statement_id": 13,
              "statement_ids": [
                13
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": {
                "numbers": {
                  "RUNNING": 0,
                  "UNKNOWN": 0,
                  "SUCCEEDED": 2,
                  "FAILED": 0
                },
                "jobs": [
                  {
                    "displayName": "count at NativeMethodAccessorImpl.java:0",
                    "dataWritten": 0,
                    "dataRead": 451,
                    "rowCount": 8,
                    "usageDescription": "",
                    "jobId": 3,
                    "name": "count at NativeMethodAccessorImpl.java:0",
                    "description": "Job group for statement 13:\ncomments_row_count = comments_single_df.count()\ncomment_col_count = len(comments_single_df.columns)\nprint(f\"shape of the comments dataframe is {comments_row_count:,}x{comment_col_count}\")",
                    "submissionTime": "2024-11-24T21:44:29.567GMT",
                    "completionTime": "2024-11-24T21:44:30.161GMT",
                    "stageIds": [
                      3,
                      4
                    ],
                    "jobGroup": "13",
                    "status": "SUCCEEDED",
                    "numTasks": 9,
                    "numActiveTasks": 0,
                    "numCompletedTasks": 1,
                    "numSkippedTasks": 8,
                    "numFailedTasks": 0,
                    "numKilledTasks": 0,
                    "numCompletedIndices": 1,
                    "numActiveStages": 0,
                    "numCompletedStages": 1,
                    "numSkippedStages": 1,
                    "numFailedStages": 0,
                    "killedTasksSummary": {}
                  },
                  {
                    "displayName": "count at NativeMethodAccessorImpl.java:0",
                    "dataWritten": 451,
                    "dataRead": 91070,
                    "rowCount": 1000008,
                    "usageDescription": "",
                    "jobId": 2,
                    "name": "count at NativeMethodAccessorImpl.java:0",
                    "description": "Job group for statement 13:\ncomments_row_count = comments_single_df.count()\ncomment_col_count = len(comments_single_df.columns)\nprint(f\"shape of the comments dataframe is {comments_row_count:,}x{comment_col_count}\")",
                    "submissionTime": "2024-11-24T21:44:23.010GMT",
                    "completionTime": "2024-11-24T21:44:29.462GMT",
                    "stageIds": [
                      2
                    ],
                    "jobGroup": "13",
                    "status": "SUCCEEDED",
                    "numTasks": 8,
                    "numActiveTasks": 0,
                    "numCompletedTasks": 8,
                    "numSkippedTasks": 0,
                    "numFailedTasks": 0,
                    "numKilledTasks": 0,
                    "numCompletedIndices": 8,
                    "numActiveStages": 0,
                    "numCompletedStages": 1,
                    "numSkippedStages": 0,
                    "numFailedStages": 0,
                    "killedTasksSummary": {}
                  }
                ],
                "limit": 20,
                "rule": "ALL_DESC"
              },
              "session_id": "4",
              "normalized_state": "finished",
              "queued_time": "2024-11-24T21:44:21.0741579Z",
              "session_start_time": null,
              "execution_start_time": "2024-11-24T21:44:21.1944334Z",
              "execution_finish_time": "2024-11-24T21:44:31.2499196Z",
              "parent_msg_id": "135569ff-8277-4355-be2c-d0a6ec694b49"
            },
            "text/plain": "StatementMeta(ba5e360d-f184-47a0-9859-76b5031b79e3, 4, 13, Finished, Available, Finished)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "shape of the comments dataframe is 1,000,000x17\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1732484671352
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# submissions_single_df.printSchema()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "ba5e360d-f184-47a0-9859-76b5031b79e3",
              "statement_id": 14,
              "statement_ids": [
                14
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": {
                "numbers": {
                  "RUNNING": 0,
                  "UNKNOWN": 0,
                  "SUCCEEDED": 0,
                  "FAILED": 0
                },
                "jobs": [],
                "limit": 20,
                "rule": "ALL_DESC"
              },
              "session_id": "4",
              "normalized_state": "finished",
              "queued_time": "2024-11-24T21:44:34.4175925Z",
              "session_start_time": null,
              "execution_start_time": "2024-11-24T21:44:34.5366607Z",
              "execution_finish_time": "2024-11-24T21:44:34.8512373Z",
              "parent_msg_id": "84037465-4deb-44ac-88f0-f7a02d9e1add"
            },
            "text/plain": "StatementMeta(ba5e360d-f184-47a0-9859-76b5031b79e3, 4, 14, Finished, Available, Finished)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "root\n |-- author: string (nullable = true)\n |-- author_flair_css_class: string (nullable = true)\n |-- author_flair_text: string (nullable = true)\n |-- created_utc: long (nullable = true)\n |-- distinguished: string (nullable = true)\n |-- domain: string (nullable = true)\n |-- edited: double (nullable = true)\n |-- id: string (nullable = true)\n |-- is_self: boolean (nullable = true)\n |-- locked: boolean (nullable = true)\n |-- num_comments: long (nullable = true)\n |-- over_18: boolean (nullable = true)\n |-- quarantine: boolean (nullable = true)\n |-- retrieved_on: long (nullable = true)\n |-- score: long (nullable = true)\n |-- selftext: string (nullable = true)\n |-- stickied: boolean (nullable = true)\n |-- subreddit: string (nullable = true)\n |-- subreddit_id: string (nullable = true)\n |-- title: string (nullable = true)\n |-- url: string (nullable = true)\n\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1732484674941
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# submissions_row_count = submissions_single_df.count()\n",
        "# submissions_col_count = len(submissions_single_df.columns)\n",
        "# print(f\"shape of the submissions dataframe is {submissions_row_count:,}x{submissions_col_count}\")"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "ba5e360d-f184-47a0-9859-76b5031b79e3",
              "statement_id": 15,
              "statement_ids": [
                15
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": {
                "numbers": {
                  "RUNNING": 0,
                  "UNKNOWN": 0,
                  "SUCCEEDED": 2,
                  "FAILED": 0
                },
                "jobs": [
                  {
                    "displayName": "count at NativeMethodAccessorImpl.java:0",
                    "dataWritten": 0,
                    "dataRead": 451,
                    "rowCount": 8,
                    "usageDescription": "",
                    "jobId": 5,
                    "name": "count at NativeMethodAccessorImpl.java:0",
                    "description": "Job group for statement 15:\nsubmissions_row_count = submissions_single_df.count()\nsubmissions_col_count = len(submissions_single_df.columns)\nprint(f\"shape of the submissions dataframe is {submissions_row_count:,}x{submissions_col_count}\")",
                    "submissionTime": "2024-11-24T21:44:37.800GMT",
                    "completionTime": "2024-11-24T21:44:38.061GMT",
                    "stageIds": [
                      6,
                      7
                    ],
                    "jobGroup": "15",
                    "status": "SUCCEEDED",
                    "numTasks": 9,
                    "numActiveTasks": 0,
                    "numCompletedTasks": 1,
                    "numSkippedTasks": 8,
                    "numFailedTasks": 0,
                    "numKilledTasks": 0,
                    "numCompletedIndices": 1,
                    "numActiveStages": 0,
                    "numCompletedStages": 1,
                    "numSkippedStages": 1,
                    "numFailedStages": 0,
                    "killedTasksSummary": {}
                  },
                  {
                    "displayName": "count at NativeMethodAccessorImpl.java:0",
                    "dataWritten": 451,
                    "dataRead": 112250,
                    "rowCount": 1000008,
                    "usageDescription": "",
                    "jobId": 4,
                    "name": "count at NativeMethodAccessorImpl.java:0",
                    "description": "Job group for statement 15:\nsubmissions_row_count = submissions_single_df.count()\nsubmissions_col_count = len(submissions_single_df.columns)\nprint(f\"shape of the submissions dataframe is {submissions_row_count:,}x{submissions_col_count}\")",
                    "submissionTime": "2024-11-24T21:44:37.467GMT",
                    "completionTime": "2024-11-24T21:44:37.768GMT",
                    "stageIds": [
                      5
                    ],
                    "jobGroup": "15",
                    "status": "SUCCEEDED",
                    "numTasks": 8,
                    "numActiveTasks": 0,
                    "numCompletedTasks": 8,
                    "numSkippedTasks": 0,
                    "numFailedTasks": 0,
                    "numKilledTasks": 0,
                    "numCompletedIndices": 8,
                    "numActiveStages": 0,
                    "numCompletedStages": 1,
                    "numSkippedStages": 0,
                    "numFailedStages": 0,
                    "killedTasksSummary": {}
                  }
                ],
                "limit": 20,
                "rule": "ALL_DESC"
              },
              "session_id": "4",
              "normalized_state": "finished",
              "queued_time": "2024-11-24T21:44:37.168481Z",
              "session_start_time": null,
              "execution_start_time": "2024-11-24T21:44:37.3243729Z",
              "execution_finish_time": "2024-11-24T21:44:38.8670122Z",
              "parent_msg_id": "88081ebf-6e0a-4393-bd64-ed406ef8d6d0"
            },
            "text/plain": "StatementMeta(ba5e360d-f184-47a0-9859-76b5031b79e3, 4, 15, Finished, Available, Finished)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "shape of the submissions dataframe is 1,000,000x21\n"
        }
      ],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1732484679015
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Reading in an entire month"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Test on a single month\n",
        "# comments_month = \"yyyy=2023/mm=11/\"\n",
        "# submissions_month = \"yyyy=2023/mm=11/\""
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "ba5e360d-f184-47a0-9859-76b5031b79e3",
              "statement_id": 16,
              "statement_ids": [
                16
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": {
                "numbers": {
                  "RUNNING": 0,
                  "UNKNOWN": 0,
                  "SUCCEEDED": 0,
                  "FAILED": 0
                },
                "jobs": [],
                "limit": 20,
                "rule": "ALL_DESC"
              },
              "session_id": "4",
              "normalized_state": "finished",
              "queued_time": "2024-11-24T21:44:42.2550711Z",
              "session_start_time": null,
              "execution_start_time": "2024-11-24T21:44:42.3757868Z",
              "execution_finish_time": "2024-11-24T21:44:42.7001358Z",
              "parent_msg_id": "b01e2a0d-7e2f-4751-a46d-04d3c1b6b748"
            },
            "text/plain": "StatementMeta(ba5e360d-f184-47a0-9859-76b5031b79e3, 4, 16, Finished, Available, Finished)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1732484682764
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# comments_months_df = spark.read.parquet(f\"{wasbs_base_url}{comments_path}{comments_month}\")\n",
        "# submissions_months_df = spark.read.parquet(f\"{wasbs_base_url}{submissions_path}{submissions_month}\")"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "ba5e360d-f184-47a0-9859-76b5031b79e3",
              "statement_id": 17,
              "statement_ids": [
                17
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": {
                "numbers": {
                  "RUNNING": 0,
                  "UNKNOWN": 0,
                  "SUCCEEDED": 2,
                  "FAILED": 0
                },
                "jobs": [
                  {
                    "displayName": "parquet at NativeMethodAccessorImpl.java:0",
                    "dataWritten": 0,
                    "dataRead": 0,
                    "rowCount": 0,
                    "usageDescription": "",
                    "jobId": 7,
                    "name": "parquet at NativeMethodAccessorImpl.java:0",
                    "description": "Job group for statement 17:\ncomments_months_df = spark.read.parquet(f\"{wasbs_base_url}{comments_path}{comments_month}\")\nsubmissions_months_df = spark.read.parquet(f\"{wasbs_base_url}{submissions_path}{submissions_month}\")",
                    "submissionTime": "2024-11-24T21:44:46.618GMT",
                    "completionTime": "2024-11-24T21:44:46.787GMT",
                    "stageIds": [
                      9
                    ],
                    "jobGroup": "17",
                    "status": "SUCCEEDED",
                    "numTasks": 1,
                    "numActiveTasks": 0,
                    "numCompletedTasks": 1,
                    "numSkippedTasks": 0,
                    "numFailedTasks": 0,
                    "numKilledTasks": 0,
                    "numCompletedIndices": 1,
                    "numActiveStages": 0,
                    "numCompletedStages": 1,
                    "numSkippedStages": 0,
                    "numFailedStages": 0,
                    "killedTasksSummary": {}
                  },
                  {
                    "displayName": "parquet at NativeMethodAccessorImpl.java:0",
                    "dataWritten": 0,
                    "dataRead": 0,
                    "rowCount": 0,
                    "usageDescription": "",
                    "jobId": 6,
                    "name": "parquet at NativeMethodAccessorImpl.java:0",
                    "description": "Job group for statement 17:\ncomments_months_df = spark.read.parquet(f\"{wasbs_base_url}{comments_path}{comments_month}\")\nsubmissions_months_df = spark.read.parquet(f\"{wasbs_base_url}{submissions_path}{submissions_month}\")",
                    "submissionTime": "2024-11-24T21:44:45.861GMT",
                    "completionTime": "2024-11-24T21:44:46.322GMT",
                    "stageIds": [
                      8
                    ],
                    "jobGroup": "17",
                    "status": "SUCCEEDED",
                    "numTasks": 1,
                    "numActiveTasks": 0,
                    "numCompletedTasks": 1,
                    "numSkippedTasks": 0,
                    "numFailedTasks": 0,
                    "numKilledTasks": 0,
                    "numCompletedIndices": 1,
                    "numActiveStages": 0,
                    "numCompletedStages": 1,
                    "numSkippedStages": 0,
                    "numFailedStages": 0,
                    "killedTasksSummary": {}
                  }
                ],
                "limit": 20,
                "rule": "ALL_DESC"
              },
              "session_id": "4",
              "normalized_state": "finished",
              "queued_time": "2024-11-24T21:44:45.1490499Z",
              "session_start_time": null,
              "execution_start_time": "2024-11-24T21:44:45.267701Z",
              "execution_finish_time": "2024-11-24T21:44:47.7163339Z",
              "parent_msg_id": "30a92103-b90b-4517-8483-677fe1ad938c"
            },
            "text/plain": "StatementMeta(ba5e360d-f184-47a0-9859-76b5031b79e3, 4, 17, Finished, Available, Finished)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1732484687787
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Initial exploration"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# comments_row_count = comments_months_df.count()\n",
        "# comment_col_count = len(comments_months_df.columns)\n",
        "# print(f\"shape of the comments dataframe is {comments_row_count:,}x{comment_col_count}\")"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "ba5e360d-f184-47a0-9859-76b5031b79e3",
              "statement_id": 18,
              "statement_ids": [
                18
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": {
                "numbers": {
                  "RUNNING": 0,
                  "UNKNOWN": 0,
                  "SUCCEEDED": 2,
                  "FAILED": 0
                },
                "jobs": [
                  {
                    "displayName": "count at NativeMethodAccessorImpl.java:0",
                    "dataWritten": 0,
                    "dataRead": 14396,
                    "rowCount": 244,
                    "usageDescription": "",
                    "jobId": 9,
                    "name": "count at NativeMethodAccessorImpl.java:0",
                    "description": "Job group for statement 18:\ncomments_row_count = comments_months_df.count()\ncomment_col_count = len(comments_months_df.columns)\nprint(f\"shape of the comments dataframe is {comments_row_count:,}x{comment_col_count}\")",
                    "submissionTime": "2024-11-24T21:44:54.571GMT",
                    "completionTime": "2024-11-24T21:44:54.692GMT",
                    "stageIds": [
                      12,
                      11
                    ],
                    "jobGroup": "18",
                    "status": "SUCCEEDED",
                    "numTasks": 245,
                    "numActiveTasks": 0,
                    "numCompletedTasks": 1,
                    "numSkippedTasks": 244,
                    "numFailedTasks": 0,
                    "numKilledTasks": 0,
                    "numCompletedIndices": 1,
                    "numActiveStages": 0,
                    "numCompletedStages": 1,
                    "numSkippedStages": 1,
                    "numFailedStages": 0,
                    "killedTasksSummary": {}
                  },
                  {
                    "displayName": "count at NativeMethodAccessorImpl.java:0",
                    "dataWritten": 14396,
                    "dataRead": 4479843,
                    "rowCount": 243870598,
                    "usageDescription": "",
                    "jobId": 8,
                    "name": "count at NativeMethodAccessorImpl.java:0",
                    "description": "Job group for statement 18:\ncomments_row_count = comments_months_df.count()\ncomment_col_count = len(comments_months_df.columns)\nprint(f\"shape of the comments dataframe is {comments_row_count:,}x{comment_col_count}\")",
                    "submissionTime": "2024-11-24T21:44:51.105GMT",
                    "completionTime": "2024-11-24T21:44:54.518GMT",
                    "stageIds": [
                      10
                    ],
                    "jobGroup": "18",
                    "status": "SUCCEEDED",
                    "numTasks": 244,
                    "numActiveTasks": 0,
                    "numCompletedTasks": 244,
                    "numSkippedTasks": 0,
                    "numFailedTasks": 0,
                    "numKilledTasks": 0,
                    "numCompletedIndices": 244,
                    "numActiveStages": 0,
                    "numCompletedStages": 1,
                    "numSkippedStages": 0,
                    "numFailedStages": 0,
                    "killedTasksSummary": {}
                  }
                ],
                "limit": 20,
                "rule": "ALL_DESC"
              },
              "session_id": "4",
              "normalized_state": "finished",
              "queued_time": "2024-11-24T21:44:50.8666948Z",
              "session_start_time": null,
              "execution_start_time": "2024-11-24T21:44:50.9928145Z",
              "execution_finish_time": "2024-11-24T21:44:56.0919439Z",
              "parent_msg_id": "6a0d6831-6d48-4a06-9f14-bbe331edc226"
            },
            "text/plain": "StatementMeta(ba5e360d-f184-47a0-9859-76b5031b79e3, 4, 18, Finished, Available, Finished)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "shape of the comments dataframe is 243,870,354x17\n"
        }
      ],
      "execution_count": 13,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1732484696218
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# submissions_row_count = submissions_months_df.count()\n",
        "# submissions_col_count = len(submissions_months_df.columns)\n",
        "# print(f\"shape of the submissions dataframe is {submissions_row_count:,}x{submissions_col_count}\")"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "ba5e360d-f184-47a0-9859-76b5031b79e3",
              "statement_id": 19,
              "statement_ids": [
                19
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": {
                "numbers": {
                  "RUNNING": 0,
                  "UNKNOWN": 0,
                  "SUCCEEDED": 2,
                  "FAILED": 0
                },
                "jobs": [
                  {
                    "displayName": "count at NativeMethodAccessorImpl.java:0",
                    "dataWritten": 0,
                    "dataRead": 2525,
                    "rowCount": 43,
                    "usageDescription": "",
                    "jobId": 11,
                    "name": "count at NativeMethodAccessorImpl.java:0",
                    "description": "Job group for statement 19:\nsubmissions_row_count = submissions_months_df.count()\nsubmissions_col_count = len(submissions_months_df.columns)\nprint(f\"shape of the submissions dataframe is {submissions_row_count:,}x{submissions_col_count}\")",
                    "submissionTime": "2024-11-24T21:44:57.406GMT",
                    "completionTime": "2024-11-24T21:44:57.461GMT",
                    "stageIds": [
                      15,
                      14
                    ],
                    "jobGroup": "19",
                    "status": "SUCCEEDED",
                    "numTasks": 44,
                    "numActiveTasks": 0,
                    "numCompletedTasks": 1,
                    "numSkippedTasks": 43,
                    "numFailedTasks": 0,
                    "numKilledTasks": 0,
                    "numCompletedIndices": 1,
                    "numActiveStages": 0,
                    "numCompletedStages": 1,
                    "numSkippedStages": 1,
                    "numFailedStages": 0,
                    "killedTasksSummary": {}
                  },
                  {
                    "displayName": "count at NativeMethodAccessorImpl.java:0",
                    "dataWritten": 2525,
                    "dataRead": 1421880,
                    "rowCount": 38107510,
                    "usageDescription": "",
                    "jobId": 10,
                    "name": "count at NativeMethodAccessorImpl.java:0",
                    "description": "Job group for statement 19:\nsubmissions_row_count = submissions_months_df.count()\nsubmissions_col_count = len(submissions_months_df.columns)\nprint(f\"shape of the submissions dataframe is {submissions_row_count:,}x{submissions_col_count}\")",
                    "submissionTime": "2024-11-24T21:44:56.306GMT",
                    "completionTime": "2024-11-24T21:44:57.380GMT",
                    "stageIds": [
                      13
                    ],
                    "jobGroup": "19",
                    "status": "SUCCEEDED",
                    "numTasks": 43,
                    "numActiveTasks": 0,
                    "numCompletedTasks": 43,
                    "numSkippedTasks": 0,
                    "numFailedTasks": 0,
                    "numKilledTasks": 0,
                    "numCompletedIndices": 43,
                    "numActiveStages": 0,
                    "numCompletedStages": 1,
                    "numSkippedStages": 0,
                    "numFailedStages": 0,
                    "killedTasksSummary": {}
                  }
                ],
                "limit": 20,
                "rule": "ALL_DESC"
              },
              "session_id": "4",
              "normalized_state": "finished",
              "queued_time": "2024-11-24T21:44:54.9276012Z",
              "session_start_time": null,
              "execution_start_time": "2024-11-24T21:44:56.2252876Z",
              "execution_finish_time": "2024-11-24T21:44:57.8216058Z",
              "parent_msg_id": "ab670d0c-03a6-4ece-b4e8-0b24db0db237"
            },
            "text/plain": "StatementMeta(ba5e360d-f184-47a0-9859-76b5031b79e3, 4, 19, Finished, Available, Finished)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "shape of the submissions dataframe is 38,107,467x21\n"
        }
      ],
      "execution_count": 14,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1732484697912
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Reading in all of the Reddit data"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "comments_df = spark.read.parquet(f\"{wasbs_base_url}{comments_path}\")\n",
        "submissions_df = spark.read.parquet(f\"{wasbs_base_url}{submissions_path}\")"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "ba5e360d-f184-47a0-9859-76b5031b79e3",
              "statement_id": 9,
              "statement_ids": [
                9
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": {
                "numbers": {
                  "FAILED": 0,
                  "RUNNING": 0,
                  "UNKNOWN": 0,
                  "SUCCEEDED": 2
                },
                "jobs": [
                  {
                    "displayName": "parquet at NativeMethodAccessorImpl.java:0",
                    "dataWritten": 0,
                    "dataRead": 0,
                    "rowCount": 0,
                    "usageDescription": "",
                    "jobId": 1,
                    "name": "parquet at NativeMethodAccessorImpl.java:0",
                    "description": "Job group for statement 9:\ncomments_df = spark.read.parquet(f\"{wasbs_base_url}{comments_path}\")\nsubmissions_df = spark.read.parquet(f\"{wasbs_base_url}{submissions_path}\")",
                    "submissionTime": "2024-11-24T22:37:18.539GMT",
                    "completionTime": "2024-11-24T22:37:18.742GMT",
                    "stageIds": [
                      1
                    ],
                    "jobGroup": "9",
                    "status": "SUCCEEDED",
                    "numTasks": 1,
                    "numActiveTasks": 0,
                    "numCompletedTasks": 1,
                    "numSkippedTasks": 0,
                    "numFailedTasks": 0,
                    "numKilledTasks": 0,
                    "numCompletedIndices": 1,
                    "numActiveStages": 0,
                    "numCompletedStages": 1,
                    "numSkippedStages": 0,
                    "numFailedStages": 0,
                    "killedTasksSummary": {}
                  },
                  {
                    "displayName": "parquet at NativeMethodAccessorImpl.java:0",
                    "dataWritten": 0,
                    "dataRead": 0,
                    "rowCount": 0,
                    "usageDescription": "",
                    "jobId": 0,
                    "name": "parquet at NativeMethodAccessorImpl.java:0",
                    "description": "Job group for statement 9:\ncomments_df = spark.read.parquet(f\"{wasbs_base_url}{comments_path}\")\nsubmissions_df = spark.read.parquet(f\"{wasbs_base_url}{submissions_path}\")",
                    "submissionTime": "2024-11-24T22:37:10.044GMT",
                    "completionTime": "2024-11-24T22:37:16.398GMT",
                    "stageIds": [
                      0
                    ],
                    "jobGroup": "9",
                    "status": "SUCCEEDED",
                    "numTasks": 1,
                    "numActiveTasks": 0,
                    "numCompletedTasks": 1,
                    "numSkippedTasks": 0,
                    "numFailedTasks": 0,
                    "numKilledTasks": 0,
                    "numCompletedIndices": 1,
                    "numActiveStages": 0,
                    "numCompletedStages": 1,
                    "numSkippedStages": 0,
                    "numFailedStages": 0,
                    "killedTasksSummary": {}
                  }
                ],
                "limit": 20,
                "rule": "ALL_DESC"
              },
              "session_id": "6",
              "normalized_state": "finished",
              "queued_time": "2024-11-24T22:37:05.6107853Z",
              "session_start_time": null,
              "execution_start_time": "2024-11-24T22:37:05.7434848Z",
              "execution_finish_time": "2024-11-24T22:37:20.3070951Z",
              "parent_msg_id": "d77edbbb-63b9-461e-a8b4-db34f75ff41e"
            },
            "text/plain": "StatementMeta(ba5e360d-f184-47a0-9859-76b5031b79e3, 6, 9, Finished, Available, Finished)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1732487840446
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "submissions_df.count()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "ba5e360d-f184-47a0-9859-76b5031b79e3",
              "statement_id": 10,
              "statement_ids": [
                10
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": {
                "numbers": {
                  "FAILED": 0,
                  "RUNNING": 0,
                  "UNKNOWN": 0,
                  "SUCCEEDED": 2
                },
                "jobs": [
                  {
                    "displayName": "count at NativeMethodAccessorImpl.java:0",
                    "dataWritten": 0,
                    "dataRead": 37447,
                    "rowCount": 638,
                    "usageDescription": "",
                    "jobId": 3,
                    "name": "count at NativeMethodAccessorImpl.java:0",
                    "description": "Job group for statement 10:\nsubmissions_df.count()",
                    "submissionTime": "2024-11-24T22:37:40.736GMT",
                    "completionTime": "2024-11-24T22:37:41.698GMT",
                    "stageIds": [
                      3,
                      4
                    ],
                    "jobGroup": "10",
                    "status": "SUCCEEDED",
                    "numTasks": 639,
                    "numActiveTasks": 0,
                    "numCompletedTasks": 1,
                    "numSkippedTasks": 638,
                    "numFailedTasks": 0,
                    "numKilledTasks": 0,
                    "numCompletedIndices": 1,
                    "numActiveStages": 0,
                    "numCompletedStages": 1,
                    "numSkippedStages": 1,
                    "numFailedStages": 0,
                    "killedTasksSummary": {}
                  },
                  {
                    "displayName": "count at NativeMethodAccessorImpl.java:0",
                    "dataWritten": 37447,
                    "dataRead": 19884041,
                    "rowCount": 567891507,
                    "usageDescription": "",
                    "jobId": 2,
                    "name": "count at NativeMethodAccessorImpl.java:0",
                    "description": "Job group for statement 10:\nsubmissions_df.count()",
                    "submissionTime": "2024-11-24T22:37:25.156GMT",
                    "completionTime": "2024-11-24T22:37:40.601GMT",
                    "stageIds": [
                      2
                    ],
                    "jobGroup": "10",
                    "status": "SUCCEEDED",
                    "numTasks": 638,
                    "numActiveTasks": 0,
                    "numCompletedTasks": 638,
                    "numSkippedTasks": 0,
                    "numFailedTasks": 0,
                    "numKilledTasks": 0,
                    "numCompletedIndices": 638,
                    "numActiveStages": 0,
                    "numCompletedStages": 1,
                    "numSkippedStages": 0,
                    "numFailedStages": 0,
                    "killedTasksSummary": {}
                  }
                ],
                "limit": 20,
                "rule": "ALL_DESC"
              },
              "session_id": "6",
              "normalized_state": "finished",
              "queued_time": "2024-11-24T22:37:22.6164337Z",
              "session_start_time": null,
              "execution_start_time": "2024-11-24T22:37:22.7467852Z",
              "execution_finish_time": "2024-11-24T22:37:43.8703498Z",
              "parent_msg_id": "17abb76d-17de-4b65-a57e-a86a4eb72891"
            },
            "text/plain": "StatementMeta(ba5e360d-f184-47a0-9859-76b5031b79e3, 6, 10, Finished, Available, Finished)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 19,
          "data": {
            "text/plain": "567890869"
          },
          "metadata": {}
        }
      ],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1732487863964
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "submissions_df.rdd.getNumPartitions()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "ba5e360d-f184-47a0-9859-76b5031b79e3",
              "statement_id": 21,
              "statement_ids": [
                21
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": {
                "numbers": {
                  "RUNNING": 0,
                  "UNKNOWN": 0,
                  "SUCCEEDED": 0,
                  "FAILED": 0
                },
                "jobs": [],
                "limit": 20,
                "rule": "ALL_DESC"
              },
              "session_id": "3",
              "normalized_state": "finished",
              "queued_time": "2024-11-24T21:28:26.9198695Z",
              "session_start_time": null,
              "execution_start_time": "2024-11-24T21:28:27.0539414Z",
              "execution_finish_time": "2024-11-24T21:28:27.9060498Z",
              "parent_msg_id": "24e12264-8683-4aab-ac25-bb9cd43a4333"
            },
            "text/plain": "StatementMeta(ba5e360d-f184-47a0-9859-76b5031b79e3, 3, 21, Finished, Available, Finished)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 41,
          "data": {
            "text/plain": "638"
          },
          "metadata": {}
        }
      ],
      "execution_count": 16,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1732483708068
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "comments_df.count()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "ba5e360d-f184-47a0-9859-76b5031b79e3",
              "statement_id": 22,
              "statement_ids": [
                22
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": {
                "numbers": {
                  "RUNNING": 0,
                  "UNKNOWN": 0,
                  "SUCCEEDED": 2,
                  "FAILED": 0
                },
                "jobs": [
                  {
                    "displayName": "count at NativeMethodAccessorImpl.java:0",
                    "dataWritten": 0,
                    "dataRead": 216943,
                    "rowCount": 3677,
                    "usageDescription": "",
                    "jobId": 17,
                    "name": "count at NativeMethodAccessorImpl.java:0",
                    "description": "Job group for statement 22:\ncomments_df.count()",
                    "submissionTime": "2024-11-24T21:29:16.491GMT",
                    "completionTime": "2024-11-24T21:29:17.242GMT",
                    "stageIds": [
                      22,
                      23
                    ],
                    "jobGroup": "22",
                    "status": "SUCCEEDED",
                    "numTasks": 3678,
                    "numActiveTasks": 0,
                    "numCompletedTasks": 1,
                    "numSkippedTasks": 3677,
                    "numFailedTasks": 0,
                    "numKilledTasks": 0,
                    "numCompletedIndices": 1,
                    "numActiveStages": 0,
                    "numCompletedStages": 1,
                    "numSkippedStages": 1,
                    "numFailedStages": 0,
                    "killedTasksSummary": {}
                  },
                  {
                    "displayName": "count at NativeMethodAccessorImpl.java:0",
                    "dataWritten": 216943,
                    "dataRead": 66832605,
                    "rowCount": 3675772635,
                    "usageDescription": "",
                    "jobId": 16,
                    "name": "count at NativeMethodAccessorImpl.java:0",
                    "description": "Job group for statement 22:\ncomments_df.count()",
                    "submissionTime": "2024-11-24T21:28:34.921GMT",
                    "completionTime": "2024-11-24T21:29:16.438GMT",
                    "stageIds": [
                      21
                    ],
                    "jobGroup": "22",
                    "status": "SUCCEEDED",
                    "numTasks": 3677,
                    "numActiveTasks": 0,
                    "numCompletedTasks": 3677,
                    "numSkippedTasks": 0,
                    "numFailedTasks": 0,
                    "numKilledTasks": 0,
                    "numCompletedIndices": 3677,
                    "numActiveStages": 0,
                    "numCompletedStages": 1,
                    "numSkippedStages": 0,
                    "numFailedStages": 0,
                    "killedTasksSummary": {}
                  }
                ],
                "limit": 20,
                "rule": "ALL_DESC"
              },
              "session_id": "3",
              "normalized_state": "finished",
              "queued_time": "2024-11-24T21:28:34.6091083Z",
              "session_start_time": null,
              "execution_start_time": "2024-11-24T21:28:34.7285382Z",
              "execution_finish_time": "2024-11-24T21:29:19.3401421Z",
              "parent_msg_id": "c3aba2b0-cb64-48b3-ae42-49e444cedc94"
            },
            "text/plain": "StatementMeta(ba5e360d-f184-47a0-9859-76b5031b79e3, 3, 22, Finished, Available, Finished)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 43,
          "data": {
            "text/plain": "3675768958"
          },
          "metadata": {}
        }
      ],
      "execution_count": 17,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1732483759466
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "comments_df.rdd.getNumPartitions()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "ba5e360d-f184-47a0-9859-76b5031b79e3",
              "statement_id": 23,
              "statement_ids": [
                23
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": {
                "numbers": {
                  "RUNNING": 0,
                  "UNKNOWN": 0,
                  "SUCCEEDED": 0,
                  "FAILED": 0
                },
                "jobs": [],
                "limit": 20,
                "rule": "ALL_DESC"
              },
              "session_id": "3",
              "normalized_state": "finished",
              "queued_time": "2024-11-24T21:30:17.5604817Z",
              "session_start_time": null,
              "execution_start_time": "2024-11-24T21:30:17.7008462Z",
              "execution_finish_time": "2024-11-24T21:30:19.8177856Z",
              "parent_msg_id": "299320c7-0e54-4772-b88c-29b31db2696a"
            },
            "text/plain": "StatementMeta(ba5e360d-f184-47a0-9859-76b5031b79e3, 3, 23, Finished, Available, Finished)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 45,
          "data": {
            "text/plain": "3677"
          },
          "metadata": {}
        }
      ],
      "execution_count": 18,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1732483819984
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "comments_df.printSchema()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "ba5e360d-f184-47a0-9859-76b5031b79e3",
              "statement_id": 22,
              "statement_ids": [
                22
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": {
                "numbers": {
                  "RUNNING": 0,
                  "UNKNOWN": 0,
                  "SUCCEEDED": 0,
                  "FAILED": 0
                },
                "jobs": [],
                "limit": 20,
                "rule": "ALL_DESC"
              },
              "session_id": "4",
              "normalized_state": "finished",
              "queued_time": "2024-11-24T21:45:14.2208138Z",
              "session_start_time": null,
              "execution_start_time": "2024-11-24T21:45:16.7908971Z",
              "execution_finish_time": "2024-11-24T21:45:17.1063296Z",
              "parent_msg_id": "7c20be23-89d4-4385-95a5-66e27121abf5"
            },
            "text/plain": "StatementMeta(ba5e360d-f184-47a0-9859-76b5031b79e3, 4, 22, Finished, Available, Finished)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "root\n |-- author: string (nullable = true)\n |-- author_flair_css_class: string (nullable = true)\n |-- author_flair_text: string (nullable = true)\n |-- body: string (nullable = true)\n |-- controversiality: long (nullable = true)\n |-- created_utc: long (nullable = true)\n |-- distinguished: string (nullable = true)\n |-- edited: double (nullable = true)\n |-- gilded: long (nullable = true)\n |-- id: string (nullable = true)\n |-- link_id: string (nullable = true)\n |-- parent_id: string (nullable = true)\n |-- retrieved_on: long (nullable = true)\n |-- score: long (nullable = true)\n |-- stickied: boolean (nullable = true)\n |-- subreddit: string (nullable = true)\n |-- subreddit_id: string (nullable = true)\n |-- yyyy: integer (nullable = true)\n |-- mm: integer (nullable = true)\n\n"
        }
      ],
      "execution_count": 17,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1732484717189
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Queries Part 1 \n",
        "\n",
        "#### Sorting Subreddits Relevant to: \n",
        "\n",
        "(A1, B3a, B13), A2b, A3a, A3b\n",
        "\n",
        "* Frustrating or frustrat and cancer (HINTS A2b)\n",
        "* cancer and doctors or trust (i.e. does not need to contain trust because trust is included in the NRC sentiment analysis) (HINTS A3a)\n",
        "* cancer and family or friends or sister or brother or mother or mom or father or mother or cousin or aunt or uncle or trust (HINTS A3b)\n",
        "\n",
        "HINTS Questions: \n",
        "\n",
        "* SeekCancerInfo: A1 | Have you ever looked for information about cancer from any source?\n",
        "* Electronic2_HealthInfo: B3a | In the past 12 months have you used the Internet to look for health or medical information?\n",
        "* MisleadingHealthInfo: B13 | How much of the health information that you see on social media do you think is false or misleading?"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, lower\n",
        "\n",
        "# Sample approximately 1% of the data and limit to 100 rows\n",
        "comments_subset_df = comments_df.sample(withReplacement=False, fraction=0.01, seed=42).limit(100)\n",
        "\n",
        "# Display the first few rows of the sampled and limited DataFrame\n",
        "comments_subset_df.show(5)\n",
        "\n",
        "# Display the size (number of rows) in the sampled and limited DataFrame\n",
        "print(f\"Number of rows in the sampled and limited DataFrame: {comments_subset_df.count()}\")\n"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "ba5e360d-f184-47a0-9859-76b5031b79e3",
              "statement_id": 11,
              "statement_ids": [
                11
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": {
                "numbers": {
                  "FAILED": 0,
                  "RUNNING": 0,
                  "UNKNOWN": 0,
                  "SUCCEEDED": 4
                },
                "jobs": [
                  {
                    "displayName": "count at NativeMethodAccessorImpl.java:0",
                    "dataWritten": 0,
                    "dataRead": 0,
                    "rowCount": 0,
                    "usageDescription": "",
                    "jobId": 7,
                    "name": "count at NativeMethodAccessorImpl.java:0",
                    "description": "Job group for statement 11:\nfrom pyspark.sql.functions import col, lower\n\n# Sample approximately 1% of the data and limit to 100 rows\ncomments_subset_df = comments_df.sample(withReplacement=False, fraction=0.01, seed=42).limit(100)\n\n# Display the first few rows of the sampled and limited DataFrame\ncomments_subset_df.show(5)\n\n# Display the size (number of rows) in the sampled and limited DataFrame\nprint(f\"Number of rows in the sampled and limited DataFrame: {comments_subset_df.count()}\")\n",
                    "submissionTime": "2024-11-24T23:06:18.538GMT",
                    "completionTime": "2024-11-24T23:06:18.717GMT",
                    "stageIds": [
                      9,
                      10
                    ],
                    "jobGroup": "11",
                    "status": "SUCCEEDED",
                    "numTasks": 3678,
                    "numActiveTasks": 0,
                    "numCompletedTasks": 1,
                    "numSkippedTasks": 3677,
                    "numFailedTasks": 0,
                    "numKilledTasks": 0,
                    "numCompletedIndices": 1,
                    "numActiveStages": 0,
                    "numCompletedStages": 1,
                    "numSkippedStages": 1,
                    "numFailedStages": 0,
                    "killedTasksSummary": {}
                  },
                  {
                    "displayName": "count at NativeMethodAccessorImpl.java:0",
                    "dataWritten": 198558,
                    "dataRead": 67264452,
                    "rowCount": 45247572,
                    "usageDescription": "",
                    "jobId": 6,
                    "name": "count at NativeMethodAccessorImpl.java:0",
                    "description": "Job group for statement 11:\nfrom pyspark.sql.functions import col, lower\n\n# Sample approximately 1% of the data and limit to 100 rows\ncomments_subset_df = comments_df.sample(withReplacement=False, fraction=0.01, seed=42).limit(100)\n\n# Display the first few rows of the sampled and limited DataFrame\ncomments_subset_df.show(5)\n\n# Display the size (number of rows) in the sampled and limited DataFrame\nprint(f\"Number of rows in the sampled and limited DataFrame: {comments_subset_df.count()}\")\n",
                    "submissionTime": "2024-11-24T23:05:50.001GMT",
                    "completionTime": "2024-11-24T23:06:18.446GMT",
                    "stageIds": [
                      8
                    ],
                    "jobGroup": "11",
                    "status": "SUCCEEDED",
                    "numTasks": 3677,
                    "numActiveTasks": 0,
                    "numCompletedTasks": 3677,
                    "numSkippedTasks": 0,
                    "numFailedTasks": 0,
                    "numKilledTasks": 0,
                    "numCompletedIndices": 3677,
                    "numActiveStages": 0,
                    "numCompletedStages": 1,
                    "numSkippedStages": 0,
                    "numFailedStages": 0,
                    "killedTasksSummary": {}
                  },
                  {
                    "displayName": "showString at NativeMethodAccessorImpl.java:0",
                    "dataWritten": 0,
                    "dataRead": 0,
                    "rowCount": 0,
                    "usageDescription": "",
                    "jobId": 5,
                    "name": "showString at NativeMethodAccessorImpl.java:0",
                    "description": "Job group for statement 11:\nfrom pyspark.sql.functions import col, lower\n\n# Sample approximately 1% of the data and limit to 100 rows\ncomments_subset_df = comments_df.sample(withReplacement=False, fraction=0.01, seed=42).limit(100)\n\n# Display the first few rows of the sampled and limited DataFrame\ncomments_subset_df.show(5)\n\n# Display the size (number of rows) in the sampled and limited DataFrame\nprint(f\"Number of rows in the sampled and limited DataFrame: {comments_subset_df.count()}\")\n",
                    "submissionTime": "2024-11-24T23:05:49.170GMT",
                    "completionTime": "2024-11-24T23:05:49.645GMT",
                    "stageIds": [
                      6,
                      7
                    ],
                    "jobGroup": "11",
                    "status": "SUCCEEDED",
                    "numTasks": 3678,
                    "numActiveTasks": 0,
                    "numCompletedTasks": 1,
                    "numSkippedTasks": 3677,
                    "numFailedTasks": 0,
                    "numKilledTasks": 0,
                    "numCompletedIndices": 1,
                    "numActiveStages": 0,
                    "numCompletedStages": 1,
                    "numSkippedStages": 1,
                    "numFailedStages": 0,
                    "killedTasksSummary": {}
                  },
                  {
                    "displayName": "showString at NativeMethodAccessorImpl.java:0",
                    "dataWritten": 86101160,
                    "dataRead": 396700700646,
                    "rowCount": 45247572,
                    "usageDescription": "",
                    "jobId": 4,
                    "name": "showString at NativeMethodAccessorImpl.java:0",
                    "description": "Job group for statement 11:\nfrom pyspark.sql.functions import col, lower\n\n# Sample approximately 1% of the data and limit to 100 rows\ncomments_subset_df = comments_df.sample(withReplacement=False, fraction=0.01, seed=42).limit(100)\n\n# Display the first few rows of the sampled and limited DataFrame\ncomments_subset_df.show(5)\n\n# Display the size (number of rows) in the sampled and limited DataFrame\nprint(f\"Number of rows in the sampled and limited DataFrame: {comments_subset_df.count()}\")\n",
                    "submissionTime": "2024-11-24T22:37:53.547GMT",
                    "completionTime": "2024-11-24T23:05:48.965GMT",
                    "stageIds": [
                      5
                    ],
                    "jobGroup": "11",
                    "status": "SUCCEEDED",
                    "numTasks": 3677,
                    "numActiveTasks": 0,
                    "numCompletedTasks": 3677,
                    "numSkippedTasks": 0,
                    "numFailedTasks": 0,
                    "numKilledTasks": 0,
                    "numCompletedIndices": 3677,
                    "numActiveStages": 0,
                    "numCompletedStages": 1,
                    "numSkippedStages": 0,
                    "numFailedStages": 0,
                    "killedTasksSummary": {}
                  }
                ],
                "limit": 20,
                "rule": "ALL_DESC"
              },
              "session_id": "6",
              "normalized_state": "finished",
              "queued_time": "2024-11-24T22:37:52.9396861Z",
              "session_start_time": null,
              "execution_start_time": "2024-11-24T22:37:53.0656255Z",
              "execution_finish_time": "2024-11-24T23:06:21.8004373Z",
              "parent_msg_id": "96d34391-c6c8-4f6e-873a-fa1c1a7d32a3"
            },
            "text/plain": "StatementMeta(ba5e360d-f184-47a0-9859-76b5031b79e3, 6, 11, Finished, Available, Finished)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "+-------------------+----------------------+-----------------+--------------------+----------------+-----------+-------------+------+------+-------+----------+----------+------------+-----+--------+--------------------+------------+----+---+\n|             author|author_flair_css_class|author_flair_text|                body|controversiality|created_utc|distinguished|edited|gilded|     id|   link_id| parent_id|retrieved_on|score|stickied|           subreddit|subreddit_id|yyyy| mm|\n+-------------------+----------------------+-----------------+--------------------+----------------+-----------+-------------+------+------+-------+----------+----------+------------+-----+--------+--------------------+------------+----+---+\n|       Jerseyman201|                  null|             null|So epic! Great to...|               0| 1717083681|         null|  null|     0|l6c7c16|t3_1d2roc1|t1_l6bjgns|  1717083698|    1|   false|ACInfinityAdvance...|   t5_4wr8cz|2024|  5|\n|           julesyxx|                  null|             null|Why a garbage per...|               0| 1717083681|         null|  null|     0|l6c7c1z|t3_1d44ggo|t1_l6c6esh|  1717083698|    0|   false| relationship_advice|    t5_2r0cn|2024|  5|\n|            zondo33|                  null|             null|          Vote BLUE.|               0| 1717083681|         null|  null|     0|l6c7c2e|t3_1d43vc9|t3_1d43vc9|  1717083698|    6|   false|  WhitePeopleTwitter|    t5_35n7t|2024|  5|\n|   StormyWaters2021|                  null|             null|X isn't determine...|               0| 1717083682|         null|  null|     0|l6c7c51|t3_1d43g0p|t1_l6bx3j6|  1717083698|    4|   false|                 mtg|    t5_2qhnp|2024|  5|\n|SonicSpiderRanger10|                  null|             null|Yeah, but I think...|               0| 1717083682|         null|  null|     0|l6c7c6h|t3_1d3wt4m|t1_l6c749e|  1717083698|    2|   false|  TopCharacterTropes|   t5_9t6uuf|2024|  5|\n+-------------------+----------------------+-----------------+--------------------+----------------+-----------+-------------+------+------+-------+----------+----------+------------+-----+--------+--------------------+------------+----+---+\nonly showing top 5 rows\n\nNumber of rows in the sampled and limited DataFrame: 100\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1732489582005
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter the subset for comments containing \"frustrat\" and \"cancer\"\n",
        "filtered_comments_subset_df = comments_subset_df.filter(\n",
        "    (lower(col(\"body\")).contains(\"frustrat\")) & (lower(col(\"body\")).contains(\"cancer\"))\n",
        ")\n",
        "\n",
        "# Preview the filtered DataFrame\n",
        "filtered_comments_subset_df.show(5)\n",
        "\n",
        "# Save the filtered subset to a test CSV file\n",
        "output_test_file = \"Test_Query_A2b.csv\"\n",
        "filtered_comments_subset_df.write.csv(output_test_file, mode=\"overwrite\", header=True)\n",
        "\n",
        "print(f\"Test results saved to {output_test_file}\")\n"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "ba5e360d-f184-47a0-9859-76b5031b79e3",
              "statement_id": 12,
              "statement_ids": [
                12
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": {
                "numbers": {
                  "FAILED": 0,
                  "RUNNING": 0,
                  "UNKNOWN": 0,
                  "SUCCEEDED": 4
                },
                "jobs": [
                  {
                    "displayName": "csv at NativeMethodAccessorImpl.java:0",
                    "dataWritten": 190,
                    "dataRead": 0,
                    "rowCount": 0,
                    "usageDescription": "",
                    "jobId": 11,
                    "name": "csv at NativeMethodAccessorImpl.java:0",
                    "description": "Job group for statement 12:\n# Filter the subset for comments containing \"frustrat\" and \"cancer\"\nfiltered_comments_subset_df = comments_subset_df.filter(\n    (lower(col(\"body\")).contains(\"frustrat\")) & (lower(col(\"body\")).contains(\"cancer\"))\n)\n\n# Preview the filtered DataFrame\nfiltered_comments_subset_df.show(5)\n\n# Save the filtered subset to a test CSV file\noutput_test_file = \"Test_Query_A2b.csv\"\nfiltered_comments_subset_df.write.csv(output_test_file, mode=\"overwrite\", header=True)\n\nprint(f\"Test results saved to {output_test_file}\")\n",
                    "submissionTime": "2024-11-25T00:01:22.764GMT",
                    "completionTime": "2024-11-25T00:01:24.055GMT",
                    "stageIds": [
                      15,
                      16
                    ],
                    "jobGroup": "12",
                    "status": "SUCCEEDED",
                    "numTasks": 3678,
                    "numActiveTasks": 0,
                    "numCompletedTasks": 1,
                    "numSkippedTasks": 3677,
                    "numFailedTasks": 0,
                    "numKilledTasks": 0,
                    "numCompletedIndices": 1,
                    "numActiveStages": 0,
                    "numCompletedStages": 1,
                    "numSkippedStages": 1,
                    "numFailedStages": 0,
                    "killedTasksSummary": {}
                  },
                  {
                    "displayName": "csv at NativeMethodAccessorImpl.java:0",
                    "dataWritten": 86101160,
                    "dataRead": 396700700646,
                    "rowCount": 45247572,
                    "usageDescription": "",
                    "jobId": 10,
                    "name": "csv at NativeMethodAccessorImpl.java:0",
                    "description": "Job group for statement 12:\n# Filter the subset for comments containing \"frustrat\" and \"cancer\"\nfiltered_comments_subset_df = comments_subset_df.filter(\n    (lower(col(\"body\")).contains(\"frustrat\")) & (lower(col(\"body\")).contains(\"cancer\"))\n)\n\n# Preview the filtered DataFrame\nfiltered_comments_subset_df.show(5)\n\n# Save the filtered subset to a test CSV file\noutput_test_file = \"Test_Query_A2b.csv\"\nfiltered_comments_subset_df.write.csv(output_test_file, mode=\"overwrite\", header=True)\n\nprint(f\"Test results saved to {output_test_file}\")\n",
                    "submissionTime": "2024-11-24T23:34:18.340GMT",
                    "completionTime": "2024-11-25T00:01:22.592GMT",
                    "stageIds": [
                      14
                    ],
                    "jobGroup": "12",
                    "status": "SUCCEEDED",
                    "numTasks": 3677,
                    "numActiveTasks": 0,
                    "numCompletedTasks": 3677,
                    "numSkippedTasks": 0,
                    "numFailedTasks": 0,
                    "numKilledTasks": 0,
                    "numCompletedIndices": 3677,
                    "numActiveStages": 0,
                    "numCompletedStages": 1,
                    "numSkippedStages": 0,
                    "numFailedStages": 0,
                    "killedTasksSummary": {}
                  },
                  {
                    "displayName": "showString at NativeMethodAccessorImpl.java:0",
                    "dataWritten": 0,
                    "dataRead": 0,
                    "rowCount": 0,
                    "usageDescription": "",
                    "jobId": 9,
                    "name": "showString at NativeMethodAccessorImpl.java:0",
                    "description": "Job group for statement 12:\n# Filter the subset for comments containing \"frustrat\" and \"cancer\"\nfiltered_comments_subset_df = comments_subset_df.filter(\n    (lower(col(\"body\")).contains(\"frustrat\")) & (lower(col(\"body\")).contains(\"cancer\"))\n)\n\n# Preview the filtered DataFrame\nfiltered_comments_subset_df.show(5)\n\n# Save the filtered subset to a test CSV file\noutput_test_file = \"Test_Query_A2b.csv\"\nfiltered_comments_subset_df.write.csv(output_test_file, mode=\"overwrite\", header=True)\n\nprint(f\"Test results saved to {output_test_file}\")\n",
                    "submissionTime": "2024-11-24T23:34:17.451GMT",
                    "completionTime": "2024-11-24T23:34:17.681GMT",
                    "stageIds": [
                      12,
                      13
                    ],
                    "jobGroup": "12",
                    "status": "SUCCEEDED",
                    "numTasks": 3678,
                    "numActiveTasks": 0,
                    "numCompletedTasks": 1,
                    "numSkippedTasks": 3677,
                    "numFailedTasks": 0,
                    "numKilledTasks": 0,
                    "numCompletedIndices": 1,
                    "numActiveStages": 0,
                    "numCompletedStages": 1,
                    "numSkippedStages": 1,
                    "numFailedStages": 0,
                    "killedTasksSummary": {}
                  },
                  {
                    "displayName": "showString at NativeMethodAccessorImpl.java:0",
                    "dataWritten": 86101160,
                    "dataRead": 396700700646,
                    "rowCount": 45247572,
                    "usageDescription": "",
                    "jobId": 8,
                    "name": "showString at NativeMethodAccessorImpl.java:0",
                    "description": "Job group for statement 12:\n# Filter the subset for comments containing \"frustrat\" and \"cancer\"\nfiltered_comments_subset_df = comments_subset_df.filter(\n    (lower(col(\"body\")).contains(\"frustrat\")) & (lower(col(\"body\")).contains(\"cancer\"))\n)\n\n# Preview the filtered DataFrame\nfiltered_comments_subset_df.show(5)\n\n# Save the filtered subset to a test CSV file\noutput_test_file = \"Test_Query_A2b.csv\"\nfiltered_comments_subset_df.write.csv(output_test_file, mode=\"overwrite\", header=True)\n\nprint(f\"Test results saved to {output_test_file}\")\n",
                    "submissionTime": "2024-11-24T23:06:42.241GMT",
                    "completionTime": "2024-11-24T23:34:17.309GMT",
                    "stageIds": [
                      11
                    ],
                    "jobGroup": "12",
                    "status": "SUCCEEDED",
                    "numTasks": 3677,
                    "numActiveTasks": 0,
                    "numCompletedTasks": 3677,
                    "numSkippedTasks": 0,
                    "numFailedTasks": 0,
                    "numKilledTasks": 0,
                    "numCompletedIndices": 3677,
                    "numActiveStages": 0,
                    "numCompletedStages": 1,
                    "numSkippedStages": 0,
                    "numFailedStages": 0,
                    "killedTasksSummary": {}
                  }
                ],
                "limit": 20,
                "rule": "ALL_DESC"
              },
              "session_id": "6",
              "normalized_state": "finished",
              "queued_time": "2024-11-24T23:06:41.6126404Z",
              "session_start_time": null,
              "execution_start_time": "2024-11-24T23:06:41.7923313Z",
              "execution_finish_time": "2024-11-25T00:01:27.7442884Z",
              "parent_msg_id": "265f2cae-755c-4376-8031-546782f6e3a0"
            },
            "text/plain": "StatementMeta(ba5e360d-f184-47a0-9859-76b5031b79e3, 6, 12, Finished, Available, Finished)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "+------+----------------------+-----------------+----+----------------+-----------+-------------+------+------+---+-------+---------+------------+-----+--------+---------+------------+----+---+\n|author|author_flair_css_class|author_flair_text|body|controversiality|created_utc|distinguished|edited|gilded| id|link_id|parent_id|retrieved_on|score|stickied|subreddit|subreddit_id|yyyy| mm|\n+------+----------------------+-----------------+----+----------------+-----------+-------------+------+------+---+-------+---------+------------+-----+--------+---------+------------+----+---+\n+------+----------------------+-----------------+----+----------------+-----------+-------------+------+------+---+-------+---------+------------+-----+--------+---------+------------+----+---+\n\nTest results saved to Test_Query_A2b.csv\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1732492888149
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Full Job \n",
        "# from pyspark.sql.functions import col, lower\n",
        "\n",
        "# # Filter comments containing \"frustrat\" and \"cancer\"\n",
        "# filtered_comments_df = comments_df.filter(\n",
        "#     (lower(col(\"body\")).contains(\"frustrat\")) & (lower(col(\"body\")).contains(\"cancer\"))\n",
        "# )\n",
        "\n",
        "# # Save the filtered comments to a CSV file\n",
        "# output_file = \"Query_A2b.csv\"\n",
        "# filtered_comments_df.write.csv(output_file, mode=\"overwrite\", header=True)\n",
        "\n",
        "# # Preview the filtered DataFrame\n",
        "# filtered_comments_df.show(5)\n"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "ba5e360d-f184-47a0-9859-76b5031b79e3",
              "statement_id": 23,
              "statement_ids": [
                23
              ],
              "state": "finished",
              "livy_statement_state": "cancelled",
              "spark_jobs": {
                "numbers": {
                  "RUNNING": 0,
                  "UNKNOWN": 0,
                  "SUCCEEDED": 0,
                  "FAILED": 1
                },
                "jobs": [
                  {
                    "displayName": "csv at NativeMethodAccessorImpl.java:0",
                    "dataWritten": 659445,
                    "dataRead": 10502572209,
                    "rowCount": 92000413,
                    "usageDescription": "",
                    "jobId": 16,
                    "name": "csv at NativeMethodAccessorImpl.java:0",
                    "description": "Job group for statement 23:\nfrom pyspark.sql.functions import col, lower\n\n# Filter comments containing \"frustrat\" and \"cancer\"\nfiltered_comments_df = comments_df.filter(\n    (lower(col(\"body\")).contains(\"frustrat\")) & (lower(col(\"body\")).contains(\"cancer\"))\n)\n\n# Save the filtered comments to a CSV file\noutput_file = \"Query_A2b.csv\"\nfiltered_comments_df.write.csv(output_file, mode=\"overwrite\", header=True)\n\n# Preview the filtered DataFrame\nfiltered_comments_df.show(5)\n",
                    "submissionTime": "2024-11-24T21:46:37.938GMT",
                    "completionTime": "2024-11-24T21:48:20.247GMT",
                    "stageIds": [
                      21
                    ],
                    "jobGroup": "23",
                    "status": "FAILED",
                    "numTasks": 3677,
                    "numActiveTasks": 0,
                    "numCompletedTasks": 92,
                    "numSkippedTasks": 0,
                    "numFailedTasks": 0,
                    "numKilledTasks": 8,
                    "numCompletedIndices": 92,
                    "numActiveStages": 0,
                    "numCompletedStages": 0,
                    "numSkippedStages": 0,
                    "numFailedStages": 1,
                    "killedTasksSummary": {
                      "Stage cancelled": 8
                    }
                  }
                ],
                "limit": 20,
                "rule": "ALL_DESC"
              },
              "session_id": "4",
              "normalized_state": "cancelled",
              "queued_time": "2024-11-24T21:46:36.8471617Z",
              "session_start_time": null,
              "execution_start_time": "2024-11-24T21:46:37.0619102Z",
              "execution_finish_time": "2024-11-24T21:48:21.8713127Z",
              "parent_msg_id": "5601befc-f3f0-4ae2-97e6-a98aa87c060b"
            },
            "text/plain": "StatementMeta(ba5e360d-f184-47a0-9859-76b5031b79e3, 4, 23, Finished, Cancelled, Cancelled)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 18,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1732484900127
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "synapse_pyspark",
      "language": "Python",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0",
      "mimetype": "text/x-python",
      "file_extension": ".py",
      "pygments_lexer": "ipython",
      "codemirror_mode": "ipython",
      "nbconvert_exporter": "python"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "synapse_pyspark"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}